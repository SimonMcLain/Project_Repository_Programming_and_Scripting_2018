# Project_Repository_Programming_and_Scripting_2018
## This README file contains my research and investigations into the Fisher's Iris data set. Here I explain the research carried out and provide references to the source material. 


Created 2018-03-26


Table of Contents
####
1. Introduction to Fisher, his Iris dataset, Data Analytics & Python
2. Summary of findings
3. Project management & project plan
4. Instructions for running the script
5. References


1. Introduction to Fisher, his Iris dataset, Data Analytics and Python 

Sir Ronald Fisher (1890-1962) is often referred to as the father of modern statistics and experimental design due to the major contributions he made to these fields. Fisher introduced the concept of variance (ANOVA), a measure of how data distributes around a mean or expected value, as well as inventing tools for modern experimental design. Fisher literally wrote the book on it: "Statistical Methods for Research Workers", rather he wrote several books on it. His work at Rothame Experimental Station in agricultural research gave him access to agricultural data enabling him to develop new theories on experiments. It's quite fortunate he applied his brilliant mind to statistics in agriculture given his other interest: eugenics, considered a respectable scientific topic in his time. 

Among Fisher's work is the Iris dataset, that consists of 50 samples from each of three species of Iris, Iris setosa, Iris virginica and Iris versicolour. Four measurements where taken from each sample. The length and breadth of petals and sepals. Statistically speaking this dataset is interesting, as it is mathmatically possible to differentiate 3 visualy similar 
(almost identical) flowers when an appropriate statistical approach be applied.

This feature has resulted in the Iris data becoming extremely popular with students of Data Analytics when learning. Data Analytics is the science of using computers and computer programming to transform information into knowledge, and potentially into action. For instance, if significant numbers of people in California start viewing a particular widget on Amazon, Amazon's computer programs will automatically ship said widgets to a local warehouse, in readiness for orders being placed, not when orders are placed, before, without human intervention at any stage. See d) below. 


Broadly speaking there are four stages of development within Data Analytics, below in order of increasing degree of automation and business value:
 a) Descriptive Analytics: 'this' just happened
 b) Predictive Analytics: 'this' might happend
 c) Prescriptive Analytics: based on the data you should do 'this'
 d) Cognitive Analytics: computer automatically did 'this' without human intervention

Python is a 'high-level' 4th generation computer language. Simply put it is easier to learn than other programming languages since the code used is broadly similar to writing making it easier to read and understand. 

It's nice to imagine the "Knights that say Ni!" planting Fisher's Iris's in their scubbery. 

2. Summary of findings




3. Project management

My approach to the management of this project is based on the Project Management Insititute methodologies and as such I have broken the project in to 5 phases:


a) Initiating
b) Planning
c) Executing
d) Steering
e) Closing

It should be noted that these phases are not intended to be sequential, rather they overlap at times. Initiating occurs for a relatively short period of time, planning occurs throughout the life of the project, executing occurs as soon as the project deliverables are understoo, steering begins shortly after planning and executing have begun and closing should be considered as verifying the project deliverables have been met and ends at mid-night on April 29th. 

Intiating Phase
During this phase I reviewed the project orientation video and supporting documentation to identify the deliverables required to obtain a passing grade. I identified times when I would be able to work on the project, given work, family and other committments. I travel internationaly almost evey week, have two children, 5 & 8 and the project co-incides with 5 weeks of home refurbishment work. I identified times when I would not be able to work on the project due to other committments.

I also used this as an opportunity to perform some investigative research. 

Planning Phase
Using Google and Microsoft Edge I identified materials which could be used during the project, downloading Python scripts and recording website addresses. Then uploading them to this repository. I also researched and creates some simple Python scripts that would calculate the average, median and standard deviation  for each of the columns in the Iris dataset. 

I also decided to use this as a learning opportunity to develop and understanding of Matplotlib for graphical representation of the Iris dataset, as well develop a basic understanding of numpy, scipy, pandas and seaborn. These decisions helped me to narrow the focus of the online resources and other materials I would be using during the project. 

Towards the end of the planning phase I decided I wanted to find code that would create a statistical summary of the Iris dataset and create some charts. I decided that a key component of the project would be a decription of what I learned about the Iris dataset from the output of the code. 

Executing Phase
During this phase I actively worked on the key deliverables which I summarise as follows:
a) A comprehensive README file
b) Evidence of thorough research into the Iris dataset and examples of interesting analyses that other have pursued
c) Writing Python scripts to investigate the Iris dataset, including annotation that demonstrates an understanding of the material and demonstrates my own work
d) Comprehesive references of sources the that have contributed to this project

Closing
During this phase I consoldated the files that I had created, checked that the key deliverables meet the requirements laid out in points a - d above. Rechecked the Python scripts run as intended, check references used, as well as spelling and grammer with the README. file. 


4. Instruction how to run the Python scripts

5. References:

Below is a list of references used during my project. Where the code created relied heavily upon work created by others I have added it to the Python Scripts. 

https://en.wikipedia.org/wiki/Iris_flower_data_set

https://study.com/academy/lesson/sir-ronald-fisher-biography-contributions-to-statistics.html

https://www.britannica.com/biography/Ronald-Aylmer-Fisher

Mark Lutz, Learning Python, 2013 O'Reilly

http://pythonhosted.org/bob.db.iris/py_api.html

https://www.youtube.com/watch?v=PlrEJfvZRNo

Python Scripts
https://medium.com/codebagng/basic-analysis-of-the-iris-data-set-using-python-2995618a6342
numpy cheat sheet
https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf

pandas cheat sheets
https://www.dataquest.io/blog/pandas-cheat-sheet/
file:///C:/Users/simon/Downloads/Pandas_Cheat_Sheet.pdf

scipy cheat sheets
https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_SciPy_Cheat_Sheet_Linear_Algebra.pdf

matlpltlib usermanual/ cheatsheet
https://matplotlib.org/Matplotlib.pdf
https://api.ning.com/files/ix5EiwUaTp0E5*jp7eiswyccuIvY2ZsTZtw4N00CRgaI9Y5fMQEYTahMiecJ8nwooZZHezoGsTkJ-duNPnb39c9Qmgg9hX4L/dc1.png
https://storage.googleapis.com/supplemental_media/udacityu/5428018709/numpy_pandas_cheatsheet.pdf


https://uk.mathworks.com/help/stats/sample-data-sets.html;jsessionid=1ed9d85bab3a1121160e7427a0a8?requestedDomain=true
https://uk.mathworks.com/matlabcentral/fileexchange/32664-iris-data-set-clustering
http://www.pymvpa.org/tutorial_datasets.html

